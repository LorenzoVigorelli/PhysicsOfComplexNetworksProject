{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "427c93fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Iterable, Set, Tuple\n",
    "import pandas as pd\n",
    "from typing import Iterable, Dict, Optional, Tuple, List, Set\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f016964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TSV_PATH = \"data/gadm1_nuts3_counties-gadm1_nuts3_counties - FB Social Connectedness Index - October 2021.tsv\"\n",
    "MAP_PATH = \"data/gadm1_nuts3_counties_levels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78e46771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Funzioni di utilità (semplici)\n",
    "# ================================\n",
    "from typing import Iterable, Dict, Optional, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "def _normalize_location_code(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Normalizza i codici location: stringa, strip, upper.\n",
    "    Non modifica il NaN.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        s.astype(\"string\")\n",
    "         .str.strip()\n",
    "         .str.upper()\n",
    "    )\n",
    "\n",
    "def _ensure_columns(df: pd.DataFrame, required: Iterable[str], where: str = \"\") -> None:\n",
    "    \"\"\"\n",
    "    Verifica che il DataFrame contenga le colonne richieste.\n",
    "    Lancia un'eccezione con messaggio chiaro in caso manchi qualcosa.\n",
    "    \"\"\"\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        loc = f\" in {where}\" if where else \"\"\n",
    "        raise ValueError(f\"Mancano colonne{loc}: {missing}\")\n",
    "\n",
    "def _preview(df: pd.DataFrame, name: str = \"DataFrame\", n: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Stampa anteprima, schema e numero righe.\n",
    "    \"\"\"\n",
    "    print(f\"== {name} – prime righe ==\")\n",
    "    display(df.head(n))\n",
    "    print(\"\\nSchema:\")\n",
    "    print(df.dtypes)\n",
    "    print(f\"\\nNumero righe: {len(df):,}\")\n",
    "\n",
    "# ===========================================\n",
    "# Lettura SCI (Facebook) e file di mapping\n",
    "# ===========================================\n",
    "def load_sci_tsv(\n",
    "    path: str,\n",
    "    sci_cols: Iterable[str] = (\"user_loc\", \"fr_loc\", \"scaled_sci\"),\n",
    "    dtype_map: Optional[Dict[str, str]] = None,\n",
    "    low_memory: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Legge il TSV del Social Connectedness Index (SCI) di Facebook.\n",
    "    - Se dtype_map è None, usa dtype ragionevoli di default.\n",
    "    - Normalizza i codici (user_loc, fr_loc).\n",
    "    \"\"\"\n",
    "    if dtype_map is None:\n",
    "        dtype_map = {\"user_loc\": \"string\", \"fr_loc\": \"string\", \"scaled_sci\": \"float64\"}\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        sep=\"\\t\",\n",
    "        usecols=list(sci_cols),\n",
    "        dtype=dtype_map,\n",
    "        low_memory=low_memory\n",
    "    )\n",
    "\n",
    "    # Normalizzazione codici location\n",
    "    if \"user_loc\" in df.columns:\n",
    "        df[\"user_loc\"] = _normalize_location_code(df[\"user_loc\"])\n",
    "    if \"fr_loc\" in df.columns:\n",
    "        df[\"fr_loc\"] = _normalize_location_code(df[\"fr_loc\"])\n",
    "\n",
    "    # Controllo colonne richieste\n",
    "    _ensure_columns(df, sci_cols, where=\"SCI TSV\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_levels_mapping(\n",
    "    path: str,\n",
    "    usecols: Iterable[str] = (\"key\", \"level\"),\n",
    "    rename_map: Dict[str, str] = {\"key\": \"location_code\", \"level\": \"level_type\"},\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Legge il file di mapping (gadm1_nuts3_counties_levels.csv).\n",
    "    Rinomina colonne in: location_code, level_type.\n",
    "    Normalizza location_code.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        usecols=list(usecols),\n",
    "        dtype=\"string\"\n",
    "    ).rename(columns=rename_map)\n",
    "\n",
    "    # Controllo colonne richieste dopo rinomina\n",
    "    _ensure_columns(df, [\"location_code\", \"level_type\"], where=\"Mapping livelli\")\n",
    "\n",
    "    # Normalizzazione codice\n",
    "    df[\"location_code\"] = _normalize_location_code(df[\"location_code\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def quick_read_inputs(\n",
    "    tsv_path: str,\n",
    "    map_path: str,\n",
    "    sci_cols: Iterable[str] = (\"user_loc\", \"fr_loc\", \"scaled_sci\"),\n",
    "    dtype_map: Optional[Dict[str, str]] = None\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Wrapper comodo: legge entrambi i file e fa una preview.\n",
    "    Ritorna (df_sci, df_map).\n",
    "    \"\"\"\n",
    "    df_sci = load_sci_tsv(tsv_path, sci_cols=sci_cols, dtype_map=dtype_map)\n",
    "    _preview(df_sci, name=\"SCI (TSV)\")\n",
    "\n",
    "    df_map = load_levels_mapping(map_path)\n",
    "    _preview(df_map, name=\"Mapping livelli\")\n",
    "\n",
    "    return df_sci, df_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abb2f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# Copertura: nodi, archi, (opz.) per paese\n",
    "# ===========================================\n",
    "from typing import Dict, Iterable, Optional, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "# --- riuso delle utility già definite ---\n",
    "def _normalize_location_code(s: pd.Series) -> pd.Series:\n",
    "    return s.astype(\"string\").str.strip().str.upper()\n",
    "\n",
    "def _ensure_columns(df: pd.DataFrame, required: Iterable[str], where: str = \"\") -> None:\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        loc = f\" in {where}\" if where else \"\"\n",
    "        raise ValueError(f\"Mancano colonne{loc}: {missing}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Estrazione insiemi di codici e mappati\n",
    "# -----------------------------------------------------------------------------\n",
    "def get_unique_location_codes(df_sci: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Ritorna tutti i codici unici presenti in user_loc ∪ fr_loc (normalizzati).\n",
    "    \"\"\"\n",
    "    _ensure_columns(df_sci, [\"user_loc\", \"fr_loc\"], where=\"SCI\")\n",
    "    u = _normalize_location_code(df_sci[\"user_loc\"])\n",
    "    v = _normalize_location_code(df_sci[\"fr_loc\"])\n",
    "    return pd.Index(u).append(pd.Index(v)).astype(\"string\").unique()\n",
    "\n",
    "def get_mapped_codes(df_map: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Ritorna i codici location_code presenti nel mapping (normalizzati).\n",
    "    \"\"\"\n",
    "    _ensure_columns(df_map, [\"location_code\"], where=\"Mapping livelli\")\n",
    "    return _normalize_location_code(df_map[\"location_code\"]).dropna().unique()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Copertura nodi\n",
    "# -----------------------------------------------------------------------------\n",
    "def compute_node_coverage(df_sci: pd.DataFrame, df_map: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Calcola copertura nodi:\n",
    "      - totale codici (SCI)\n",
    "      - codici mappati (presenti in df_map)\n",
    "      - codici non mappati (lista)\n",
    "    Ritorna (df_unmapped, summary_dict)\n",
    "    \"\"\"\n",
    "    sci_codes = pd.Series(get_unique_location_codes(df_sci), name=\"location_code\")\n",
    "    map_codes = pd.Series(get_mapped_codes(df_map), name=\"location_code\")\n",
    "\n",
    "    total_codes = sci_codes.size\n",
    "    mapped_mask = sci_codes.isin(set(map_codes))\n",
    "    mapped_count = int(mapped_mask.sum())\n",
    "    unmapped = sci_codes[~mapped_mask].to_frame().drop_duplicates().sort_values(\"location_code\").reset_index(drop=True)\n",
    "\n",
    "    summary = {\n",
    "        \"total_unique_codes\": int(total_codes),\n",
    "        \"mapped_unique_codes\": int(mapped_count),\n",
    "        \"unmapped_unique_codes\": int(total_codes - mapped_count),\n",
    "        \"node_coverage_pct\": (mapped_count / total_codes * 100.0) if total_codes else 0.0,\n",
    "    }\n",
    "    return unmapped, summary\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Copertura archi\n",
    "# -----------------------------------------------------------------------------\n",
    "def compute_edge_coverage(df_sci: pd.DataFrame, df_map: pd.DataFrame) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Copertura archi: quante righe SCI hanno BOTH endpoints mappati.\n",
    "    \"\"\"\n",
    "    _ensure_columns(df_sci, [\"user_loc\", \"fr_loc\"], where=\"SCI\")\n",
    "    mapped_set = set(get_mapped_codes(df_map))\n",
    "\n",
    "    u = _normalize_location_code(df_sci[\"user_loc\"])\n",
    "    v = _normalize_location_code(df_sci[\"fr_loc\"])\n",
    "\n",
    "    both_mapped_mask = u.isin(mapped_set) & v.isin(mapped_set)\n",
    "    total_rows = int(len(df_sci))\n",
    "    valid_rows = int(both_mapped_mask.sum())\n",
    "\n",
    "    return {\n",
    "        \"total_rows\": total_rows,\n",
    "        \"valid_rows_both_mapped\": valid_rows,\n",
    "        \"edge_coverage_pct\": (valid_rows / total_rows * 100.0) if total_rows else 0.0,\n",
    "    }\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Copertura per paese (richiede country_ISO3 nel mapping)\n",
    "# -----------------------------------------------------------------------------\n",
    "def compute_country_coverage(\n",
    "    df_sci: pd.DataFrame,\n",
    "    df_map: pd.DataFrame,\n",
    "    iso_col: str = \"country_ISO3\",\n",
    "    keep_only_intra_country: bool = True\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Calcola copertura per paese:\n",
    "      - nodi unici mappati che appaiono in archi validi\n",
    "      - archi validi (righe SCI con entrambi i capi mappati)\n",
    "      - opzionalmente solo archi intra-country (ISO uguali)\n",
    "    Se df_map non contiene iso_col → ritorna None e stampa un avviso.\n",
    "    \"\"\"\n",
    "    if iso_col not in df_map.columns:\n",
    "        print(f\"[AVVISO] Colonna '{iso_col}' assente nel mapping: copertura per paese non calcolata.\")\n",
    "        return None\n",
    "\n",
    "    _ensure_columns(df_sci, [\"user_loc\", \"fr_loc\"], where=\"SCI\")\n",
    "    # mapping code -> ISO\n",
    "    df_map_local = df_map[[\"location_code\", iso_col]].copy()\n",
    "    df_map_local[\"location_code\"] = _normalize_location_code(df_map_local[\"location_code\"])\n",
    "\n",
    "    code2iso = df_map_local.dropna().drop_duplicates(\"location_code\").set_index(\"location_code\")[iso_col]\n",
    "\n",
    "    # aggiunge ISO a partire dai codici\n",
    "    sci = df_sci[[\"user_loc\", \"fr_loc\"]].copy()\n",
    "    sci[\"user_loc\"] = _normalize_location_code(sci[\"user_loc\"])\n",
    "    sci[\"fr_loc\"]   = _normalize_location_code(sci[\"fr_loc\"])\n",
    "\n",
    "    sci[\"iso_from\"] = sci[\"user_loc\"].map(code2iso)\n",
    "    sci[\"iso_to\"]   = sci[\"fr_loc\"].map(code2iso)\n",
    "\n",
    "    # tiene solo righe con entrambi mappati\n",
    "    sci_valid = sci.dropna(subset=[\"iso_from\", \"iso_to\"]).copy()\n",
    "\n",
    "    if keep_only_intra_country:\n",
    "        sci_valid = sci_valid[sci_valid[\"iso_from\"] == sci_valid[\"iso_to\"]].copy()\n",
    "\n",
    "    # archi per paese (conteggio righe)\n",
    "    edges_by_country = (sci_valid\n",
    "                        .groupby(\"iso_from\", as_index=False)\n",
    "                        .agg(edges=(\"user_loc\", \"size\"))\n",
    "                        .rename(columns={\"iso_from\": iso_col}))\n",
    "\n",
    "    # nodi per paese (nodi che compaiono almeno in un arco valido)\n",
    "    nodes_from = sci_valid[[\"iso_from\", \"user_loc\"]].rename(columns={\"iso_from\": iso_col, \"user_loc\": \"loc\"})\n",
    "    nodes_to   = sci_valid[[\"iso_to\", \"fr_loc\"]].rename(columns={\"iso_to\": iso_col, \"fr_loc\": \"loc\"})\n",
    "    nodes_all  = pd.concat([nodes_from, nodes_to], ignore_index=True).drop_duplicates()\n",
    "\n",
    "    nodes_by_country = (nodes_all.groupby(iso_col, as_index=False)\n",
    "                        .agg(nodes=(\"loc\", \"nunique\")))\n",
    "\n",
    "    # merge nodi + archi e percentuale sul totale archi\n",
    "    country_cov = edges_by_country.merge(nodes_by_country, on=iso_col, how=\"outer\").fillna(0)\n",
    "    country_cov[\"edges\"] = country_cov[\"edges\"].astype(int)\n",
    "    country_cov[\"nodes\"] = country_cov[\"nodes\"].astype(int)\n",
    "\n",
    "    total_edges = int(country_cov[\"edges\"].sum()) if len(country_cov) else 0\n",
    "    if total_edges > 0:\n",
    "        country_cov[\"edges_pct\"] = 100.0 * country_cov[\"edges\"] / total_edges\n",
    "    else:\n",
    "        country_cov[\"edges_pct\"] = 0.0\n",
    "\n",
    "    # ordina per importanza (più archi, poi più nodi)\n",
    "    country_cov = country_cov.sort_values([\"edges\", \"nodes\"], ascending=False).reset_index(drop=True)\n",
    "    return country_cov\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Wrapper pratico: stampa un mini-report\n",
    "# -----------------------------------------------------------------------------\n",
    "def coverage_report(df_sci: pd.DataFrame, df_map: pd.DataFrame, top_n: int = 10) -> None:\n",
    "    # nodi\n",
    "    unmapped_nodes, node_summary = compute_node_coverage(df_sci, df_map)\n",
    "    print(\"== Copertura NODI ==\")\n",
    "    for k, v in node_summary.items():\n",
    "        print(f\"- {k}: {v}\")\n",
    "    if len(unmapped_nodes) > 0:\n",
    "        print(f\"\\nEsempi codici NON mappati ({min(10, len(unmapped_nodes))}):\")\n",
    "        display(unmapped_nodes.head(10))\n",
    "\n",
    "    # archi\n",
    "    edge_summary = compute_edge_coverage(df_sci, df_map)\n",
    "    print(\"\\n== Copertura ARCHI ==\")\n",
    "    for k, v in edge_summary.items():\n",
    "        print(f\"- {k}: {v}\")\n",
    "\n",
    "    # per paese (se disponibile)\n",
    "    country_cov = compute_country_coverage(df_sci, df_map)\n",
    "    if country_cov is not None and len(country_cov):\n",
    "        print(\"\\n== Copertura PER PAESE (prime righe) ==\")\n",
    "        display(country_cov.head(top_n))\n",
    "    else:\n",
    "        print(\"\\n== Copertura PER PAESE ==\")\n",
    "        print(\"Mapping senza 'country_ISO3' → se vuoi questa sezione, aggiungi la colonna a df_map.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94706b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_cols = [\"user_loc\", \"fr_loc\", \"scaled_sci\"]\n",
    "dtype_map = {\"user_loc\": \"string\", \"fr_loc\": \"string\", \"scaled_sci\": \"float64\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c425c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== SCI (TSV) – prime righe ==\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_loc</th>\n",
       "      <th>fr_loc</th>\n",
       "      <th>scaled_sci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>ABW</td>\n",
       "      <td>11264841.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABW</td>\n",
       "      <td>AGO1</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABW</td>\n",
       "      <td>AGO10</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABW</td>\n",
       "      <td>AGO11</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABW</td>\n",
       "      <td>AGO12</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_loc fr_loc  scaled_sci\n",
       "0      ABW    ABW  11264841.0\n",
       "1      ABW   AGO1        38.0\n",
       "2      ABW  AGO10        34.0\n",
       "3      ABW  AGO11        32.0\n",
       "4      ABW  AGO12        23.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema:\n",
      "user_loc      string[python]\n",
      "fr_loc        string[python]\n",
      "scaled_sci           float64\n",
      "dtype: object\n",
      "\n",
      "Numero righe: 63,824,121\n",
      "== Mapping livelli – prime righe ==\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_code</th>\n",
       "      <th>level_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AND</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATG</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABW</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BHS</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRB</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_code level_type\n",
       "0           AND    country\n",
       "1           ATG    country\n",
       "2           ABW    country\n",
       "3           BHS    country\n",
       "4           BRB    country"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema:\n",
      "location_code    string[python]\n",
      "level_type       string[python]\n",
      "dtype: object\n",
      "\n",
      "Numero righe: 8,008\n"
     ]
    }
   ],
   "source": [
    "df_sci, df_map = quick_read_inputs(\n",
    "    tsv_path=TSV_PATH,\n",
    "    map_path=MAP_PATH,\n",
    "    sci_cols=sci_cols,\n",
    "    dtype_map=dtype_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d81f529e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level_type\n",
       "COUNTY     3229\n",
       "GADM1      1839\n",
       "NUTS3      1522\n",
       "GADM2      1370\n",
       "COUNTRY      48\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map['level_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ffcea3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# NODES BUILDER (NUTS3, GADM2, US COUNTIES) – funzioni base\n",
    "# =========================================================\n",
    "from typing import Iterable, Dict, Optional, Tuple, List, Set\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# ---------- utility già viste ----------\n",
    "def _normalize_location_code(s: pd.Series) -> pd.Series:\n",
    "    return s.astype(\"string\").str.strip().str.upper()\n",
    "\n",
    "def _ensure_columns(df: pd.DataFrame, required: Iterable[str], where: str = \"\") -> None:\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        loc = f\" in {where}\" if where else \"\"\n",
    "        raise ValueError(f\"Mancano colonne{loc}: {missing}\")\n",
    "\n",
    "# ---------- 0) Target codes: presenti in SCI e nel mapping, per tipo ----------\n",
    "def select_target_codes(\n",
    "    df_sci: pd.DataFrame,\n",
    "    df_map: pd.DataFrame,\n",
    "    level_types: Iterable[str] = (\"NUTS3\", \"GADM2\", \"COUNTY\")\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ritorna un df (location_code, level_type) con SOLO i codici:\n",
    "      - presenti in df_sci (in user_loc o fr_loc)\n",
    "      - presenti nel mapping df_map\n",
    "      - il cui level_type è tra quelli richiesti\n",
    "    \"\"\"\n",
    "    _ensure_columns(df_sci, [\"user_loc\", \"fr_loc\"], \"SCI\")\n",
    "    _ensure_columns(df_map, [\"location_code\", \"level_type\"], \"Mapping\")\n",
    "\n",
    "    sci_codes = pd.Index(_normalize_location_code(df_sci[\"user_loc\"])) \\\n",
    "                  .append(pd.Index(_normalize_location_code(df_sci[\"fr_loc\"]))) \\\n",
    "                  .unique()\n",
    "\n",
    "    df_map2 = df_map.copy()\n",
    "    df_map2[\"location_code\"] = _normalize_location_code(df_map2[\"location_code\"])\n",
    "    df_map2 = df_map2[df_map2[\"level_type\"].str.upper().isin([t.upper() for t in level_types])]\n",
    "\n",
    "    target = (df_map2[df_map2[\"location_code\"].isin(set(sci_codes))]\n",
    "              .drop_duplicates(subset=[\"location_code\", \"level_type\"])\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "    print(f\"[INFO] Target codes selezionati: {len(target):,} (tipi: {sorted(target['level_type'].unique())})\")\n",
    "    return target\n",
    "\n",
    "# ---------- 1) Letture geografiche + representative point ----------\n",
    "def _representative_points(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    gdf = gdf.to_crs(4326)\n",
    "    gdf[\"geometry\"] = gdf[\"geometry\"].representative_point()\n",
    "    gdf[\"latitude\"] = gdf.geometry.y\n",
    "    gdf[\"longitude\"] = gdf.geometry.x\n",
    "    return gdf\n",
    "\n",
    "# NUTS3\n",
    "def load_nuts3_points(\n",
    "    nuts_geojson_path: str,\n",
    "    code_col: Optional[str] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Legge il GeoJSON NUTS e restituisce (code, lat, lon) per LEVL 3.\n",
    "    Prova a indovinare la colonna codice: NUTS_ID / NUTS_ID_ / id.\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(nuts_geojson_path)\n",
    "    # filtra livello 3 se presente\n",
    "    levl_col = next((c for c in [\"LEVL_CODE\", \"LEVL\", \"LEVEL\"] if c in gdf.columns), None)\n",
    "    if levl_col is not None:\n",
    "        gdf = gdf[gdf[levl_col].astype(str).isin([\"3\", 3])].copy()\n",
    "\n",
    "    # determina colonna codice\n",
    "    candidates = [code_col] if code_col else None\n",
    "    if not candidates or candidates == [None]:\n",
    "        candidates = [c for c in [\"NUTS_ID\", \"nuts_id\", \"ID\", \"id\"] if c in gdf.columns]\n",
    "    if not candidates:\n",
    "        raise ValueError(\"Non trovo una colonna codice per NUTS (es. 'NUTS_ID'). Passa code_col=...\")\n",
    "\n",
    "    cc = candidates[0]\n",
    "    gdf = gdf.rename(columns={cc: \"code\"})\n",
    "    gdf = _representative_points(gdf[[\"code\", \"geometry\"]].dropna())\n",
    "    gdf[\"code\"] = _normalize_location_code(gdf[\"code\"])\n",
    "    return gdf[[\"code\", \"latitude\", \"longitude\"]].drop_duplicates(\"code\")\n",
    "\n",
    "# GADM2 (GADM v4.10 GPKG)\n",
    "def load_gadm2_points(gadm_gpkg_path: str, layer: str = \"gadm_410\", code_col: str = \"GID_2\"):\n",
    "    \"\"\"\n",
    "    Estrae GADM livello 2 come (code, lat, lon) dal file GADM v4.10.\n",
    "    - Usa il layer 'gadm_410' (che contiene tutti i livelli)\n",
    "    - Seleziona la colonna GID_2 come identificativo ADM2\n",
    "    - Filtra le righe dove GID_2 non è NaN\n",
    "    - Calcola un punto rappresentativo all'interno di ciascun poligono\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(gadm_gpkg_path, layer=layer)\n",
    "\n",
    "    if code_col not in gdf.columns:\n",
    "        raise ValueError(f\"La colonna {code_col!r} non esiste nel layer {layer}. Colonne trovate: {list(gdf.columns)}\")\n",
    "\n",
    "    # tieni solo livello 2\n",
    "    gdf2 = gdf[~gdf[code_col].isna()].copy()\n",
    "    gdf2 = gdf2.rename(columns={code_col: \"code\"})\n",
    "\n",
    "    # calcolo punto rappresentativo\n",
    "    gdf2 = gdf2.to_crs(4326)\n",
    "    gdf2[\"geometry\"] = gdf2.geometry.representative_point()\n",
    "    gdf2[\"latitude\"] = gdf2.geometry.y\n",
    "    gdf2[\"longitude\"] = gdf2.geometry.x\n",
    "\n",
    "    # normalizza codice\n",
    "    gdf2[\"code\"] = gdf2[\"code\"].astype(\"string\").str.strip().str.upper()\n",
    "\n",
    "    out = gdf2[[\"code\", \"latitude\", \"longitude\"]].drop_duplicates(\"code\")\n",
    "    print(f\"[GADM2] Caricate {len(out):,} unità ADM2 uniche da {gadm_gpkg_path}\")\n",
    "    return out\n",
    "\n",
    "# US COUNTIES\n",
    "def load_us_counties_points(\n",
    "    counties_geojson_path: str,\n",
    "    code_col: Optional[str] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Estrae punti per contee USA.\n",
    "    Colonne codice comuni: 'GEOID', 'geoid', 'FIPS', 'fips'.\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(counties_geojson_path)\n",
    "    candidates = [code_col] if code_col else None\n",
    "    if not candidates or candidates == [None]:\n",
    "        candidates = [c for c in [\"GEOID\", \"geoid\", \"FIPS\", \"fips\"] if c in gdf.columns]\n",
    "    if not candidates:\n",
    "        raise ValueError(\"Non trovo una colonna codice per US counties (es. 'GEOID'). Passa code_col=...\")\n",
    "\n",
    "    cc = candidates[0]\n",
    "    gdf = gdf.rename(columns={cc: \"code\"})\n",
    "    # normalizza: GEOID/FIPS come stringa zero-padded (5)\n",
    "    gdf[\"code\"] = gdf[\"code\"].astype(str).str.zfill(5)\n",
    "    gdf = _representative_points(gdf[[\"code\", \"geometry\"]].dropna())\n",
    "    gdf[\"code\"] = _normalize_location_code(gdf[\"code\"])\n",
    "    return gdf[[\"code\", \"latitude\", \"longitude\"]].drop_duplicates(\"code\")\n",
    "\n",
    "# ---------- 2) Join: tieni SOLO i codici target (presenti in SCI + mapping) ----------\n",
    "def build_nodes_for_type(\n",
    "    target_codes: pd.DataFrame,\n",
    "    type_name: str,\n",
    "    source_df_points: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Mantiene solo i codici di 'type_name' presenti in target_codes\n",
    "    e con un match nei punti (source_df_points).\n",
    "    Ritorna: nodeLabel, latitude, longitude (+ type).\n",
    "    \"\"\"\n",
    "    type_mask = target_codes[\"level_type\"].str.upper() == type_name.upper()\n",
    "    wanted = target_codes.loc[type_mask, [\"location_code\"]].rename(columns={\"location_code\": \"code\"}).copy()\n",
    "    wanted[\"code\"] = _normalize_location_code(wanted[\"code\"])\n",
    "\n",
    "    pts = source_df_points.copy()\n",
    "    pts[\"code\"] = _normalize_location_code(pts[\"code\"])\n",
    "\n",
    "    out = wanted.merge(pts, on=\"code\", how=\"inner\")\n",
    "    out = out.rename(columns={\"code\": \"nodeLabel\"})\n",
    "    out[\"level_type\"] = type_name.upper()\n",
    "    return out[[\"nodeLabel\", \"latitude\", \"longitude\", \"level_type\"]].drop_duplicates(\"nodeLabel\")\n",
    "\n",
    "# ---------- 3) Assemblaggio node_list finale ----------\n",
    "def assemble_node_list(\n",
    "    nuts_nodes: Optional[pd.DataFrame] = None,\n",
    "    gadm_nodes: Optional[pd.DataFrame] = None,\n",
    "    county_nodes: Optional[pd.DataFrame] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Concatena le tre sorgenti, assegna nodeID stabile per label.\n",
    "    Output colonne richieste: nodeID,nodeLabel,latitude,longitude\n",
    "    (se serve puoi conservare 'level_type' per debug).\n",
    "    \"\"\"\n",
    "    frames = [df for df in [nuts_nodes, gadm_nodes, county_nodes] if df is not None and len(df)]\n",
    "    if not frames:\n",
    "        raise ValueError(\"Nessun nodo fornito.\")\n",
    "\n",
    "    nodes = pd.concat(frames, ignore_index=True).drop_duplicates(\"nodeLabel\")\n",
    "    nodes = nodes.sort_values(\"nodeLabel\").reset_index(drop=True)\n",
    "    nodes.insert(0, \"nodeID\", range(1, len(nodes) + 1))\n",
    "    return nodes[[\"nodeID\", \"nodeLabel\", \"latitude\", \"longitude\"]]\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_gadm2_mapping_code(code: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Converte codici mapping tipo 'BGD1_1' in 'BGD.1.1_1' (formato GADM v4 GID_2).\n",
    "    Ritorna None se il formato non combacia.\n",
    "    \"\"\"\n",
    "    if code is None or pd.isna(code):\n",
    "        return None\n",
    "    s = str(code).strip().upper()\n",
    "    m = re.fullmatch(r'([A-Z]{3})(\\d+)_([0-9]+)', s)\n",
    "    if not m:\n",
    "        return None\n",
    "    iso3, adm1, adm2 = m.groups()\n",
    "    return f\"{iso3}.{int(adm1)}.{int(adm2)}_1\"\n",
    "\n",
    "def normalize_county_mapping_code(code: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Converte codici mapping tipo 'USA06091' in '06091' (GEOID a 5 cifre).\n",
    "    Gestisce anche 'USA31039' ecc. Restituisce None se non riconosce.\n",
    "    \"\"\"\n",
    "    if code is None or pd.isna(code):\n",
    "        return None\n",
    "    s = str(code).strip().upper()\n",
    "    if s.startswith(\"USA\"):\n",
    "        s = s[3:]\n",
    "    s = re.sub(r'\\D', '', s)  # lascia solo cifre\n",
    "    if len(s) == 5:\n",
    "        return s\n",
    "    # se lunghezze diverse, prova a zfill\n",
    "    if 1 <= len(s) <= 5:\n",
    "        return s.zfill(5)\n",
    "    return None\n",
    "\n",
    "def build_nodes_for_type_with_transform(\n",
    "    target_codes: pd.DataFrame,\n",
    "    type_name: str,\n",
    "    source_df_points: pd.DataFrame,\n",
    "    transform_fn=None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Come build_nodes_for_type, ma permette di trasformare i codici del mapping\n",
    "    prima del join coi 'points' (es. GADM2 'BGD1_1' -> 'BGD.1.1_1').\n",
    "    \"\"\"\n",
    "    mask = target_codes[\"level_type\"].str.upper() == type_name.upper()\n",
    "    wanted = target_codes.loc[mask, [\"location_code\"]].copy()\n",
    "    wanted[\"location_code\"] = wanted[\"location_code\"].astype(\"string\").str.strip().str.upper()\n",
    "\n",
    "    if transform_fn is not None:\n",
    "        wanted[\"code\"] = wanted[\"location_code\"].map(transform_fn)\n",
    "    else:\n",
    "        wanted[\"code\"] = wanted[\"location_code\"]\n",
    "\n",
    "    # rimuovi codici non trasformabili\n",
    "    wanted = wanted.dropna(subset=[\"code\"]).drop_duplicates(\"code\")\n",
    "\n",
    "    pts = source_df_points.copy()\n",
    "    pts[\"code\"] = pts[\"code\"].astype(\"string\").str.strip().str.upper()\n",
    "\n",
    "    out = wanted.merge(pts, on=\"code\", how=\"inner\")\n",
    "    out = out.rename(columns={\"code\": \"nodeLabel\"})\n",
    "    out[\"level_type\"] = type_name.upper()\n",
    "    return out[[\"nodeLabel\", \"latitude\", \"longitude\", \"level_type\"]].drop_duplicates(\"nodeLabel\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0939f12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer trovati in data/gadm_410.gpkg:\n",
      " 1. gadm_410\n"
     ]
    }
   ],
   "source": [
    "import fiona\n",
    "\n",
    "gpkg_path = \"data/gadm_410.gpkg\"  # metti qui il tuo percorso\n",
    "\n",
    "layers = fiona.listlayers(gpkg_path)\n",
    "\n",
    "print(f\"Layer trovati in {gpkg_path}:\")\n",
    "for i, lyr in enumerate(layers, 1):\n",
    "    print(f\"{i:>2}. {lyr}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c148be27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne disponibili in NUTS3 GeoJSON:\n",
      "['LEVL_CODE', 'NUTS_ID', 'CNTR_CODE', 'NAME_LATN', 'NUTS_NAME', 'MOUNT_TYPE', 'URBN_TYPE', 'COAST_TYPE', 'geometry']\n",
      "\n",
      "Prime righe:\n",
      "   LEVL_CODE NUTS_ID CNTR_CODE             NAME_LATN             NUTS_NAME  MOUNT_TYPE  URBN_TYPE  COAST_TYPE  \\\n",
      "0          3   CZ052        CZ  Královéhradecký kraj  Královéhradecký kraj           4          2           3   \n",
      "1          3   CZ053        CZ       Pardubický kraj       Pardubický kraj           4          3           3   \n",
      "2          3   CZ063        CZ         Kraj Vysočina         Kraj Vysočina           4          3           3   \n",
      "3          3   CZ064        CZ     Jihomoravský kraj     Jihomoravský kraj           4          2           3   \n",
      "4          3   CZ071        CZ        Olomoucký kraj        Olomoucký kraj           2          2           3   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((16.10732 50.66207, 16.33255 50.59246...  \n",
      "1  POLYGON ((16.8042 49.59881, 16.39363 49.58061,...  \n",
      "2  POLYGON ((16.39363 49.58061, 16.25967 49.27462...  \n",
      "3  POLYGON ((17.15943 49.27462, 17.27319 49.05789...  \n",
      "4  POLYGON ((17.4296 50.25451, 17.17647 49.95354,...  \n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "nuts_path = \"data/NUTS_RG_60M_2016_4326_LEVL_3.geojson\"\n",
    "\n",
    "# carico solo poche righe\n",
    "nuts_sample = gpd.read_file(nuts_path, rows=5)\n",
    "\n",
    "print(\"Colonne disponibili in NUTS3 GeoJSON:\")\n",
    "print(list(nuts_sample.columns))\n",
    "print(\"\\nPrime righe:\")\n",
    "print(nuts_sample.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89c768c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping field geo_point_2d: unsupported OGR type: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne disponibili in US counties GeoJSON:\n",
      "['intptlat', 'countyfp_nozero', 'countyns', 'stusab', 'csafp', 'state_name', 'aland', 'geoid', 'namelsad', 'countyfp', 'awater', 'classfp', 'lsad', 'name', 'funcstat', 'metdivfp', 'cbsafp', 'intptlon', 'statefp', 'mtfcc', 'geometry']\n",
      "\n",
      "Prime righe:\n",
      "      intptlat countyfp_nozero  countyns stusab csafp    state_name        aland  geoid          namelsad countyfp  \\\n",
      "0  +43.0066030             135  01266975     SD  None  South Dakota   1349873585  46135    Yankton County      135   \n",
      "1  +41.5929185              49  00277289     CA  None    California  10225096402  06049      Modoc County      049   \n",
      "2  +32.2388026             235  00347593     GA  None       Georgia    645583957  13235    Pulaski County      235   \n",
      "3  +39.1642619              13  00424208     IL   476      Illinois    657422422  17013    Calhoun County      013   \n",
      "4  +30.2064437               5  00558403     LA  None     Louisiana    751259388  22005  Ascension Parish      005   \n",
      "\n",
      "      awater classfp lsad       name funcstat metdivfp cbsafp      intptlon statefp  mtfcc  \\\n",
      "0   28676615      H1   06    Yankton        A     None  49460  -097.3883614      46  G4020   \n",
      "1  661284408      H1   06      Modoc        A     None   None  -120.7183704      06  G4020   \n",
      "2    5046606      H1   06    Pulaski        A     None   None  -083.4818454      13  G4020   \n",
      "3   77044161      H1   06    Calhoun        A     None  41180  -090.6662949      17  G4020   \n",
      "4   32965758      H1   15  Ascension        A     None  12940  -090.9125023      22  G4020   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((-97.51843 43.16903, -97.49807 43.169...  \n",
      "1  POLYGON ((-121.4489 41.47281, -121.44891 41.47...  \n",
      "2  POLYGON ((-83.6065 32.26751, -83.60621 32.2756...  \n",
      "3  POLYGON ((-90.71598 39.19147, -90.716 39.19155...  \n",
      "4  POLYGON ((-91.0122 30.33565, -91.0118 30.33575...  \n"
     ]
    }
   ],
   "source": [
    "counties_path = \"data/us-county-boundaries.geojson\"\n",
    "\n",
    "counties_sample = gpd.read_file(counties_path, rows=5)\n",
    "\n",
    "print(\"Colonne disponibili in US counties GeoJSON:\")\n",
    "print(list(counties_sample.columns))\n",
    "print(\"\\nPrime righe:\")\n",
    "print(counties_sample.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d72bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "def inspect_gadm2(gpkg_path: str, layer: str = \"gadm_410\", prefer_code_cols=(\"GID_2\",\"ID_2\",\"GID2\")):\n",
    "    \"\"\"\n",
    "    Ispeziona il tuo GPKG GADM4 e mostra cosa c'è a livello 2.\n",
    "    - Tenta di individuare la colonna codice ADM2 (priorità: GID_2).\n",
    "    - Filtra le righe ADM2 (non-NaN nella colonna individuata).\n",
    "    - Stampa info utili + anteprima.\n",
    "    Ritorna (gdf_full, gdf_adm2, code_col).\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(gpkg_path, layer=layer)\n",
    "    print(f\"[INFO] Caricato layer='{layer}' con {len(gdf):,} feature\")\n",
    "    print(f\"[INFO] CRS: {gdf.crs}\")\n",
    "    print(\"[INFO] Colonne disponibili:\")\n",
    "    print(list(gdf.columns))\n",
    "\n",
    "    # 1) individua colonna codice ADM2\n",
    "    cols_up = {c.upper(): c for c in gdf.columns}\n",
    "    code_col = None\n",
    "    for pref in prefer_code_cols:\n",
    "        if pref in cols_up:\n",
    "            code_col = cols_up[pref]\n",
    "            break\n",
    "    if code_col is None:\n",
    "        # fallback: qualunque colonna che sembri un identificativo di livello 2\n",
    "        candidates = [orig for up, orig in cols_up.items() if up.endswith(\"_2\") or \"GID\" in up]\n",
    "        if not candidates:\n",
    "            raise ValueError(\"Non trovo una colonna codice per ADM2 (tipo 'GID_2' o 'ID_2').\")\n",
    "        code_col = candidates[0]\n",
    "\n",
    "    print(f\"[INFO] Colonna codice ADM2 individuata: {code_col!r}\")\n",
    "\n",
    "    # 2) filtra solo le righe ADM2 (codice non nullo)\n",
    "    gdf_adm2 = gdf[~gdf[code_col].isna()].copy()\n",
    "    print(f\"[INFO] Righe ADM2 (non-NaN su {code_col}): {len(gdf_adm2):,}\")\n",
    "\n",
    "    # 3) statistiche veloci su ADM2\n",
    "    # codici unici\n",
    "    unique_codes = gdf_adm2[code_col].astype(\"string\").str.strip().str.upper().nunique()\n",
    "    print(f\"[INFO] Codici ADM2 unici: {unique_codes:,}\")\n",
    "\n",
    "    # tipo geometria\n",
    "    geom_types = gdf_adm2.geom_type.value_counts().to_dict()\n",
    "    print(f\"[INFO] Geometrie (conteggio per tipo): {geom_types}\")\n",
    "\n",
    "    # anteprima colonne tipiche se presenti\n",
    "    candidates_name = [c for c in [\"NAME_0\",\"NAME_1\",\"NAME_2\",\"GID_0\",\"GID_1\",\"GID_2\"] if c in gdf_adm2.columns]\n",
    "    show_cols = [code_col] + candidates_name\n",
    "    show_cols = [c for c in show_cols if c in gdf_adm2.columns]\n",
    "    show_cols = list(dict.fromkeys(show_cols))  # dedupe e preserva ordine\n",
    "\n",
    "    print(\"\\n== Anteprima ADM2 (prime 5 righe) ==\")\n",
    "    display(gdf_adm2[show_cols].head())\n",
    "\n",
    "    # esempi di codici\n",
    "    print(\"\\n== Esempi di codici ADM2 ==\")\n",
    "    display(\n",
    "        gdf_adm2[[code_col]]\n",
    "        .astype(\"string\").dropna()\n",
    "        .drop_duplicates()\n",
    "        .head(10)\n",
    "    )\n",
    "\n",
    "    # missing per alcune colonne utili (se esistono)\n",
    "    check_cols = [c for c in [\"NAME_0\",\"NAME_1\",\"NAME_2\",\"GID_0\",\"GID_1\",\"GID_2\"] if c in gdf_adm2.columns]\n",
    "    if check_cols:\n",
    "        print(\"\\n== Missing count su colonne comuni ==\")\n",
    "        display(gdf_adm2[check_cols].isna().sum().to_frame(\"missing\"))\n",
    "\n",
    "    return gdf, gdf_adm2, code_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac36c99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Caricato layer='gadm_410' con 356,508 feature\n",
      "[INFO] CRS: EPSG:4326\n",
      "[INFO] Colonne disponibili:\n",
      "['UID', 'GID_0', 'NAME_0', 'VARNAME_0', 'GID_1', 'NAME_1', 'VARNAME_1', 'NL_NAME_1', 'ISO_1', 'HASC_1', 'CC_1', 'TYPE_1', 'ENGTYPE_1', 'VALIDFR_1', 'GID_2', 'NAME_2', 'VARNAME_2', 'NL_NAME_2', 'HASC_2', 'CC_2', 'TYPE_2', 'ENGTYPE_2', 'VALIDFR_2', 'GID_3', 'NAME_3', 'VARNAME_3', 'NL_NAME_3', 'HASC_3', 'CC_3', 'TYPE_3', 'ENGTYPE_3', 'VALIDFR_3', 'GID_4', 'NAME_4', 'VARNAME_4', 'CC_4', 'TYPE_4', 'ENGTYPE_4', 'VALIDFR_4', 'GID_5', 'NAME_5', 'CC_5', 'TYPE_5', 'ENGTYPE_5', 'GOVERNEDBY', 'SOVEREIGN', 'DISPUTEDBY', 'REGION', 'VARREGION', 'COUNTRY', 'CONTINENT', 'SUBCONT', 'geometry']\n",
      "[INFO] Colonna codice ADM2 individuata: 'GID_2'\n",
      "[INFO] Righe ADM2 (non-NaN su GID_2): 356,508\n",
      "[INFO] Codici ADM2 unici: 47,218\n",
      "[INFO] Geometrie (conteggio per tipo): {'MultiPolygon': 356508}\n",
      "\n",
      "== Anteprima ADM2 (prime 5 righe) ==\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID_2</th>\n",
       "      <th>NAME_0</th>\n",
       "      <th>NAME_1</th>\n",
       "      <th>NAME_2</th>\n",
       "      <th>GID_0</th>\n",
       "      <th>GID_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG.1.1_1</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Badakhshan</td>\n",
       "      <td>Baharak</td>\n",
       "      <td>AFG</td>\n",
       "      <td>AFG.1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG.1.2_1</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Badakhshan</td>\n",
       "      <td>Darwaz</td>\n",
       "      <td>AFG</td>\n",
       "      <td>AFG.1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG.1.3_1</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Badakhshan</td>\n",
       "      <td>Fayzabad</td>\n",
       "      <td>AFG</td>\n",
       "      <td>AFG.1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG.1.4_1</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Badakhshan</td>\n",
       "      <td>Ishkashim</td>\n",
       "      <td>AFG</td>\n",
       "      <td>AFG.1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG.1.5_1</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Badakhshan</td>\n",
       "      <td>Jurm</td>\n",
       "      <td>AFG</td>\n",
       "      <td>AFG.1_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GID_2       NAME_0      NAME_1     NAME_2 GID_0    GID_1\n",
       "0  AFG.1.1_1  Afghanistan  Badakhshan    Baharak   AFG  AFG.1_1\n",
       "1  AFG.1.2_1  Afghanistan  Badakhshan     Darwaz   AFG  AFG.1_1\n",
       "2  AFG.1.3_1  Afghanistan  Badakhshan   Fayzabad   AFG  AFG.1_1\n",
       "3  AFG.1.4_1  Afghanistan  Badakhshan  Ishkashim   AFG  AFG.1_1\n",
       "4  AFG.1.5_1  Afghanistan  Badakhshan       Jurm   AFG  AFG.1_1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Esempi di codici ADM2 ==\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG.1.1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG.1.2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG.1.3_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG.1.4_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG.1.5_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AFG.1.6_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AFG.1.7_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AFG.1.8_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AFG.1.9_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AFG.1.10_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GID_2\n",
       "0   AFG.1.1_1\n",
       "1   AFG.1.2_1\n",
       "2   AFG.1.3_1\n",
       "3   AFG.1.4_1\n",
       "4   AFG.1.5_1\n",
       "5   AFG.1.6_1\n",
       "6   AFG.1.7_1\n",
       "7   AFG.1.8_1\n",
       "8   AFG.1.9_1\n",
       "9  AFG.1.10_1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Missing count su colonne comuni ==\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NAME_0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID_0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID_1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID_2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        missing\n",
       "NAME_0        0\n",
       "NAME_1        0\n",
       "NAME_2        0\n",
       "GID_0         0\n",
       "GID_1         0\n",
       "GID_2         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdf_full, gdf_adm2, gadm_code_col = inspect_gadm2(\"data/gadm_410.gpkg\", layer=\"gadm_410\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5b5eeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Target codes selezionati: 6,117 (tipi: ['COUNTY', 'GADM2', 'NUTS3'])\n"
     ]
    }
   ],
   "source": [
    "# ---------- 0) Restrizione ai codici presenti in SCI + mapping ----------\n",
    "target = select_target_codes(\n",
    "    df_sci=df_sci,\n",
    "    df_map=df_map,                # deve avere 'location_code' e 'level_type'\n",
    "    level_types=(\"NUTS3\", \"GADM2\", \"COUNTY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b1c9763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    code   latitude  longitude\n",
      "0  CZ052  50.321427  15.885255\n",
      "1  CZ053  49.985521  16.154792\n",
      "2  CZ063  49.411861  15.657920\n",
      "3  CZ064  49.186884  16.707571\n",
      "4  CZ071  49.861124  17.031093 1522\n"
     ]
    }
   ],
   "source": [
    "# ---------- 1) Carico punti per ciascun tipo ----------\n",
    "# NUTS3\n",
    "nuts_pts = load_nuts3_points(\n",
    "    nuts_geojson_path=\"data/NUTS_RG_60M_2016_4326_LEVL_3.geojson\", \n",
    "    # code_col=\"NUTS_ID\"  # di default prova a trovarlo da solo\n",
    ")\n",
    "print(nuts_pts.head(), len(nuts_pts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b144f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping field geo_point_2d: unsupported OGR type: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    code   latitude   longitude\n",
      "0  46135  42.983868  -97.398039\n",
      "1  06049  41.590862 -120.723734\n",
      "2  13235  32.254118  -83.487584\n",
      "3  17013  39.134326  -90.655446\n",
      "4  22005  30.204743  -90.891998 3233\n"
     ]
    }
   ],
   "source": [
    "# US counties\n",
    "county_pts = load_us_counties_points(\n",
    "    counties_geojson_path=\"data/us-county-boundaries.geojson\",\n",
    "    # code_col=\"GEOID\"    # se il file usa 'geoid' o 'FIPS', specifica qui\n",
    ")\n",
    "print(county_pts.head(), len(county_pts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8dd3d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GADM2] Caricate 47,218 unità ADM2 uniche da data/gadm_410.gpkg\n",
      "        code   latitude  longitude\n",
      "0  AFG.1.1_1  36.941952  71.128464\n",
      "1  AFG.1.2_1  38.221411  70.953644\n",
      "2  AFG.1.3_1  37.101351  70.442711\n",
      "3  AFG.1.4_1  36.864491  71.429559\n",
      "4  AFG.1.5_1  36.621590  70.865658 47218\n"
     ]
    }
   ],
   "source": [
    "# GADM2 (GPKG 4.10) – se fallisce, prova a cambiare 'layer' o 'code_col'\n",
    "gadm_pts = load_gadm2_points(\n",
    "    gadm_gpkg_path=\"data/gadm_410.gpkg\",\n",
    "    # layer=\"ADM_2\",      # se serve: \"ADM_ADM_2\" / \"ADM_2\" a seconda del file\n",
    "    # code_col=\"GID_2\"    # tipico per GADM v4\n",
    ")\n",
    "print(gadm_pts.head(), len(gadm_pts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9bf8fbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUTS3 selezionati: 1522\n",
      "GADM2 selezionati: 82\n",
      "COUNTY selezionati: 3225\n"
     ]
    }
   ],
   "source": [
    "# GADM2: mapping BGD1_1 -> GADM GID_2 (BGD.1.1_1)\n",
    "gadm_nodes = build_nodes_for_type_with_transform(\n",
    "    target_codes=target,\n",
    "    type_name=\"GADM2\",\n",
    "    source_df_points=gadm_pts,                 # ottenuto da load_gadm2_points(...)\n",
    "    transform_fn=normalize_gadm2_mapping_code  # << trasformazione chiave\n",
    ")\n",
    "\n",
    "# COUNTY: mapping USA06091 -> GEOID '06091'\n",
    "county_nodes = build_nodes_for_type_with_transform(\n",
    "    target_codes=target,\n",
    "    type_name=\"COUNTY\",\n",
    "    source_df_points=county_pts,                # ottenuto da load_us_counties_points(...)\n",
    "    transform_fn=normalize_county_mapping_code  # << trasformazione chiave\n",
    ")\n",
    "\n",
    "# NUTS3 rimane invariato (già combacia con NUTS_ID)\n",
    "nuts_nodes = build_nodes_for_type_with_transform(\n",
    "    target_codes=target,\n",
    "    type_name=\"NUTS3\",\n",
    "    source_df_points=nuts_pts,\n",
    "    transform_fn=None\n",
    ")\n",
    "\n",
    "print(\"NUTS3 selezionati:\", len(nuts_nodes))\n",
    "print(\"GADM2 selezionati:\", len(gadm_nodes))\n",
    "print(\"COUNTY selezionati:\", len(county_nodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0f6554b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUTS3 selezionati: 1522\n",
      "GADM2 selezionati: 0\n",
      "COUNTY selezionati: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodeID</th>\n",
       "      <th>nodeLabel</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AL011</td>\n",
       "      <td>41.657501</td>\n",
       "      <td>20.253305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AL012</td>\n",
       "      <td>41.390292</td>\n",
       "      <td>19.623216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AL013</td>\n",
       "      <td>42.160768</td>\n",
       "      <td>20.294509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AL014</td>\n",
       "      <td>41.786721</td>\n",
       "      <td>19.820903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AL015</td>\n",
       "      <td>42.200779</td>\n",
       "      <td>19.724310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nodeID nodeLabel   latitude  longitude\n",
       "0       1     AL011  41.657501  20.253305\n",
       "1       2     AL012  41.390292  19.623216\n",
       "2       3     AL013  42.160768  20.294509\n",
       "3       4     AL014  41.786721  19.820903\n",
       "4       5     AL015  42.200779  19.724310"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totale nodi: 1,522\n"
     ]
    }
   ],
   "source": [
    "# ---------- 2) Tieni SOLO i nodi apparsi in SCI + mapping ----------\n",
    "nuts_nodes   = build_nodes_for_type(target, \"NUTS3\", nuts_pts)\n",
    "gadm_nodes   = build_nodes_for_type(target, \"GADM2\", gadm_pts)\n",
    "county_nodes = build_nodes_for_type(target, \"COUNTY\", county_pts)\n",
    "\n",
    "print(\"NUTS3 selezionati:\", len(nuts_nodes))\n",
    "print(\"GADM2 selezionati:\", len(gadm_nodes))\n",
    "print(\"COUNTY selezionati:\", len(county_nodes))\n",
    "\n",
    "node_list = assemble_node_list(nuts_nodes, gadm_nodes, county_nodes)\n",
    "display(node_list.head())\n",
    "print(f\"Totale nodi: {len(node_list):,}\")\n",
    "node_list.to_csv(\"node_list.csv\", index=False)\n",
    "\n",
    "\n",
    "# Salva il file nel formato richiesto\n",
    "node_list.to_csv(\"node_list.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "627edb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_code</th>\n",
       "      <th>level_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6638</th>\n",
       "      <td>BGD1_1</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6639</th>\n",
       "      <td>BGD1_2</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6640</th>\n",
       "      <td>BGD1_3</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6641</th>\n",
       "      <td>BGD1_4</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6642</th>\n",
       "      <td>BGD1_5</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6643</th>\n",
       "      <td>BGD1_6</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6644</th>\n",
       "      <td>BGD2_7</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6645</th>\n",
       "      <td>BGD2_8</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6646</th>\n",
       "      <td>BGD2_9</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6647</th>\n",
       "      <td>BGD2_10</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6648</th>\n",
       "      <td>BGD2_11</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6649</th>\n",
       "      <td>BGD2_12</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6650</th>\n",
       "      <td>BGD2_13</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6651</th>\n",
       "      <td>BGD2_14</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6652</th>\n",
       "      <td>BGD2_15</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6653</th>\n",
       "      <td>BGD2_16</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6654</th>\n",
       "      <td>BGD2_17</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6655</th>\n",
       "      <td>BGD3_18</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6656</th>\n",
       "      <td>BGD3_19</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6657</th>\n",
       "      <td>BGD3_20</td>\n",
       "      <td>GADM2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     location_code level_type\n",
       "6638        BGD1_1      GADM2\n",
       "6639        BGD1_2      GADM2\n",
       "6640        BGD1_3      GADM2\n",
       "6641        BGD1_4      GADM2\n",
       "6642        BGD1_5      GADM2\n",
       "6643        BGD1_6      GADM2\n",
       "6644        BGD2_7      GADM2\n",
       "6645        BGD2_8      GADM2\n",
       "6646        BGD2_9      GADM2\n",
       "6647       BGD2_10      GADM2\n",
       "6648       BGD2_11      GADM2\n",
       "6649       BGD2_12      GADM2\n",
       "6650       BGD2_13      GADM2\n",
       "6651       BGD2_14      GADM2\n",
       "6652       BGD2_15      GADM2\n",
       "6653       BGD2_16      GADM2\n",
       "6654       BGD2_17      GADM2\n",
       "6655       BGD3_18      GADM2\n",
       "6656       BGD3_19      GADM2\n",
       "6657       BGD3_20      GADM2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map[df_map[\"level_type\"].str.upper() == \"GADM2\"].head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "702a971d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_code</th>\n",
       "      <th>level_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>USA31039</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>USA53069</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3411</th>\n",
       "      <td>USA35011</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>USA31109</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>USA31129</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3414</th>\n",
       "      <td>USA72085</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>USA46099</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3416</th>\n",
       "      <td>USA48327</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3417</th>\n",
       "      <td>USA06091</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>USA21053</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>USA39063</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>USA48189</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>USA01027</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>USA48011</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>USA39003</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>USA13189</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3425</th>\n",
       "      <td>USA55111</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3426</th>\n",
       "      <td>USA05137</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>USA41063</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3428</th>\n",
       "      <td>USA42007</td>\n",
       "      <td>COUNTY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     location_code level_type\n",
       "3409      USA31039     COUNTY\n",
       "3410      USA53069     COUNTY\n",
       "3411      USA35011     COUNTY\n",
       "3412      USA31109     COUNTY\n",
       "3413      USA31129     COUNTY\n",
       "3414      USA72085     COUNTY\n",
       "3415      USA46099     COUNTY\n",
       "3416      USA48327     COUNTY\n",
       "3417      USA06091     COUNTY\n",
       "3418      USA21053     COUNTY\n",
       "3419      USA39063     COUNTY\n",
       "3420      USA48189     COUNTY\n",
       "3421      USA01027     COUNTY\n",
       "3422      USA48011     COUNTY\n",
       "3423      USA39003     COUNTY\n",
       "3424      USA13189     COUNTY\n",
       "3425      USA55111     COUNTY\n",
       "3426      USA05137     COUNTY\n",
       "3427      USA41063     COUNTY\n",
       "3428      USA42007     COUNTY"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map[df_map[\"level_type\"].str.upper() == \"COUNTY\"].head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17805d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
